#!/usr/bin/env python3
"""
Markdownæ•æ„Ÿä¿¡æ¯æ›¿æ¢è„šæœ¬

åŠŸèƒ½ï¼š
1. æ ¹æ®CSVå­—å…¸æ–‡ä»¶ä¸­çš„è§„åˆ™ï¼Œæ‰«æå¹¶æ›¿æ¢markdownæ–‡ä»¶ä¸­çš„æ•æ„Ÿä¿¡æ¯
2. æ”¯æŒå¤šç§å¤„ç†åŠ¨ä½œï¼šmanualã€ipv4ã€ipv6ã€domainã€urlç­‰
3. äº¤äº’å¼ç¡®è®¤æ›¿æ¢è¿‡ç¨‹
4. ä¿ç•™markdownçš„é“¾æ¥å’Œå›¾ç‰‡å¼•ç”¨æ ¼å¼
"""

import argparse
import csv
import re
import hashlib
import ipaddress
import urllib.parse
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Callable, Any
from dataclasses import dataclass
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class Rule:
    """æ›¿æ¢è§„åˆ™"""
    category: str
    match_type: str  # 'keyword' æˆ– 'regex'
    pattern: str
    priority: int
    action: str
    compiled_pattern: re.Pattern = None
    
    def __post_init__(self):
        """ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼"""
        if self.match_type == 'keyword':
            # å…³é”®å­—è½¬æ¢ä¸ºæ­£åˆ™è¡¨è¾¾å¼ï¼Œæ·»åŠ å•è¯è¾¹ç•Œ
            escaped_pattern = re.escape(self.pattern)
            self.compiled_pattern = re.compile(f'\\b{escaped_pattern}\\b', re.IGNORECASE)
        elif self.match_type == 'regex':
            self.compiled_pattern = re.compile(self.pattern, re.IGNORECASE)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åŒ¹é…æ–¹å¼: {self.match_type}")

@dataclass 
class Match:
    """åŒ¹é…ç»“æœ"""
    rule: Rule
    start: int
    end: int
    text: str
    groups: Dict[str, str]
    context_before: str
    context_after: str

class SensitiveDataReplacer:
    """æ•æ„Ÿæ•°æ®æ›¿æ¢å™¨"""
    
    def __init__(self, context_chars: int = 20):
        self.context_chars = context_chars
        self.rules: List[Rule] = []
        self.actions: Dict[str, Callable] = {
            'manual': self._action_manual,
            'ipv4': self._action_ipv4,
            'ipv6': self._action_ipv6, 
            'domain': self._action_domain,
            'url': self._action_url,
        }
        
        # IPåœ°å€æ˜ å°„ç¼“å­˜
        self.ipv4_cache: Dict[str, str] = {}
        self.ipv6_cache: Dict[str, str] = {}
        self.domain_cache: Dict[str, str] = {}
        
    def load_rules(self, csv_file: str):
        """åŠ è½½CSVè§„åˆ™æ–‡ä»¶"""
        logger.info(f"åŠ è½½è§„åˆ™æ–‡ä»¶: {csv_file}")
        
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader)  # è·³è¿‡è¡¨å¤´
            
            for row_num, row in enumerate(reader, 2):
                if len(row) < 5:
                    logger.warning(f"ç¬¬{row_num}è¡Œæ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡: {row}")
                    continue
                    
                category, match_type, pattern, priority_str, action = row[:5]
                
                try:
                    priority = int(priority_str)
                except ValueError:
                    logger.error(f"ç¬¬{row_num}è¡Œä¼˜å…ˆçº§æ— æ•ˆ: {priority_str}")
                    continue
                
                # æ£€æŸ¥å¤„ç†åŠ¨ä½œæ˜¯å¦å­˜åœ¨
                if action not in self.actions:
                    logger.error(f"ç¬¬{row_num}è¡Œå¤„ç†åŠ¨ä½œä¸å­˜åœ¨: {action}")
                    logger.error(f"å¯ç”¨çš„å¤„ç†åŠ¨ä½œ: {', '.join(self.actions.keys())}")
                    raise ValueError(f"ä¸æ”¯æŒçš„å¤„ç†åŠ¨ä½œ: {action}")
                
                rule = Rule(category, match_type, pattern, priority, action)
                self.rules.append(rule)
                logger.info(f"åŠ è½½è§„åˆ™: {category} - {match_type} - {action} (ä¼˜å…ˆçº§: {priority})")
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        self.rules.sort(key=lambda r: r.priority)
        logger.info(f"æ€»å…±åŠ è½½äº† {len(self.rules)} æ¡è§„åˆ™")
    
    def _get_context(self, text: str, start: int, end: int) -> Tuple[str, str]:
        """è·å–åŒ¹é…å†…å®¹çš„ä¸Šä¸‹æ–‡"""
        context_start = max(0, start - self.context_chars)
        context_end = min(len(text), end + self.context_chars)
        
        context_before = text[context_start:start]
        context_after = text[end:context_end]
        
        return context_before, context_after
    
    def _is_in_markdown_link_or_image(self, text: str, start: int, end: int) -> bool:
        """æ£€æŸ¥åŒ¹é…ä½ç½®æ˜¯å¦åœ¨markdowné“¾æ¥æˆ–å›¾ç‰‡ä¸­"""
        # æŸ¥æ‰¾å‰é¢çš„markdownè¯­æ³•
        before_text = text[:start]
        after_text = text[end:]
        
        # æ£€æŸ¥æ˜¯å¦åœ¨é“¾æ¥ä¸­ [text](url) æˆ– ![alt](url)
        link_pattern = r'!?\[[^\]]*\]\([^)]*$'
        if re.search(link_pattern, before_text):
            # æ£€æŸ¥åé¢æ˜¯å¦æœ‰é—­åˆçš„ )
            if ')' in after_text:
                return True
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å¼•ç”¨é“¾æ¥ä¸­ [text][ref] æˆ– ![alt][ref]
        ref_pattern = r'!?\[[^\]]*\]\[[^\]]*$'
        if re.search(ref_pattern, before_text):
            if ']' in after_text:
                return True
        
        # æ£€æŸ¥æ˜¯å¦åœ¨é“¾æ¥å®šä¹‰ä¸­ [ref]: url
        def_pattern = r'^\s*\[[^\]]+\]:\s*[^\s]*$'
        # æ‰¾åˆ°å½“å‰è¡Œ
        line_start = before_text.rfind('\n') + 1
        line_end = text.find('\n', end)
        if line_end == -1:
            line_end = len(text)
        current_line = text[line_start:line_end]
        
        if re.match(def_pattern, current_line):
            return True
        
        return False
    
    def find_matches(self, text: str) -> List[Match]:
        """åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…é¡¹"""
        matches = []
        
        for rule in self.rules:
            for match in rule.compiled_pattern.finditer(text):
                start, end = match.span()
                
                # æ£€æŸ¥æ˜¯å¦åœ¨markdowné“¾æ¥æˆ–å›¾ç‰‡ä¸­
                if self._is_in_markdown_link_or_image(text, start, end):
                    logger.debug(f"è·³è¿‡markdowné“¾æ¥/å›¾ç‰‡ä¸­çš„åŒ¹é…: {match.group()}")
                    continue
                
                context_before, context_after = self._get_context(text, start, end)
                
                # è·å–å‘½åç»„
                groups = match.groupdict()
                
                matches.append(Match(
                    rule=rule,
                    start=start,
                    end=end,
                    text=match.group(),
                    groups=groups,
                    context_before=context_before,
                    context_after=context_after
                ))
        
        # æŒ‰ä½ç½®æ’åºï¼Œé¿å…é‡å æ›¿æ¢é—®é¢˜
        matches.sort(key=lambda m: m.start)
        return matches
    
    def _hash_to_range(self, input_str: str, min_val: int, max_val: int) -> int:
        """å°†å­—ç¬¦ä¸²å“ˆå¸Œåˆ°æŒ‡å®šèŒƒå›´å†…çš„æ•´æ•°"""
        hash_obj = hashlib.md5(input_str.encode('utf-8'))
        hash_int = int(hash_obj.hexdigest(), 16)
        return min_val + (hash_int % (max_val - min_val + 1))
    
    def _action_manual(self, context_before: str, original: str, **kwargs) -> str:
        """æ‰‹åŠ¨æ›¿æ¢å¤„ç†åŠ¨ä½œ"""
        print(f"\n=== æ‰‹åŠ¨æ›¿æ¢ ===")
        print(f"ä¸Šä¸‹æ–‡: ...{context_before}[{original}]...")
        print(f"åŸå§‹å†…å®¹: {original}")
        
        if kwargs:
            print(f"å‘½åç»„å‚æ•°: {kwargs}")
            print("å¯ç”¨å˜é‡å:")
            for key in kwargs.keys():
                print(f"  - {{{key}}}")
        
        while True:
            template = input("è¯·è¾“å…¥æ›¿æ¢æ¨¡æ¿ (ç•™ç©ºè·³è¿‡): ").strip()
            if not template:
                return original
            
            try:
                result = template.format(**kwargs)
                print(f"æ›¿æ¢ç»“æœ: {result}")
                confirm = input("ç¡®è®¤æ›¿æ¢? [y/N]: ").strip().lower()
                if confirm in ['y', 'yes', 'Y']:
                    return result
                elif confirm in ['n', 'no', 'N', '']:
                    continue
            except KeyError as e:
                print(f"æ¨¡æ¿é”™è¯¯: æœªçŸ¥å˜é‡ {e}")
            except Exception as e:
                print(f"æ¨¡æ¿é”™è¯¯: {e}")
    
    def _action_ipv4(self, context_before: str, original: str, **kwargs) -> str:
        """IPv4åœ°å€å¤„ç†åŠ¨ä½œ"""
        if original in self.ipv4_cache:
            return self.ipv4_cache[original]
        
        try:
            ip = ipaddress.IPv4Address(original)
            ip_int = int(ip)
            
            # å°†IPv4åœ°å€æ˜ å°„åˆ°240.0.0.0-255.255.255.254èŒƒå›´
            # ä¿æŒç½‘æ®µæ¦‚å¿µï¼šä½¿ç”¨åŸIPçš„ç½‘æ®µç»“æ„
            octets = str(ip).split('.')
            
            # åŸºäºåŸå§‹IPç”Ÿæˆä¸€è‡´çš„æ˜ å°„
            hash_seed = f"ipv4_{original}"
            
            # ç¬¬ä¸€ä¸ªå…«ä½ç»„ï¼š240-255
            first_octet = self._hash_to_range(f"{hash_seed}_1", 240, 255)
            
            # å…¶ä»–å…«ä½ç»„ï¼šåŸºäºåŸå§‹å€¼è¿›è¡Œæ˜ å°„
            second_octet = self._hash_to_range(f"{hash_seed}_2_{octets[1]}", 0, 255)
            third_octet = self._hash_to_range(f"{hash_seed}_3_{octets[2]}", 0, 255)  
            fourth_octet = self._hash_to_range(f"{hash_seed}_4_{octets[3]}", 1, 254)  # é¿å….0å’Œ.255
            
            fake_ip = f"{first_octet}.{second_octet}.{third_octet}.{fourth_octet}"
            self.ipv4_cache[original] = fake_ip
            
            logger.info(f"IPv4æ˜ å°„: {original} -> {fake_ip}")
            return fake_ip
            
        except ipaddress.AddressValueError:
            logger.warning(f"æ— æ•ˆçš„IPv4åœ°å€: {original}")
            return original
    
    def _action_ipv6(self, context_before: str, original: str, **kwargs) -> str:
        """IPv6åœ°å€å¤„ç†åŠ¨ä½œ"""
        if original in self.ipv6_cache:
            return self.ipv6_cache[original]
        
        try:
            ip = ipaddress.IPv6Address(original)
            
            # æ˜ å°„åˆ°FC00::/8èŒƒå›´
            hash_seed = f"ipv6_{original}"
            
            # ç”ŸæˆFC00::/8èŒƒå›´å†…çš„åœ°å€
            # FC00::/8 = FC00:0000:0000:0000:0000:0000:0000:0000 åˆ° FDFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF:FFFF
            
            # ä¿ç•™åŸå§‹åœ°å€çš„ç»“æ„ç‰¹å¾
            parts = str(ip.exploded).split(':')
            fake_parts = ['fc00']  # å›ºå®šå‰ç¼€
            
            for i in range(1, 8):
                if i < len(parts):
                    part_hash = self._hash_to_range(f"{hash_seed}_{i}_{parts[i]}", 0, 0xFFFF)
                else:
                    part_hash = self._hash_to_range(f"{hash_seed}_{i}", 0, 0xFFFF)
                fake_parts.append(f"{part_hash:04x}")
            
            fake_ip = ':'.join(fake_parts)
            # å‹ç¼©è¡¨ç¤º
            fake_ip = str(ipaddress.IPv6Address(fake_ip))
            
            self.ipv6_cache[original] = fake_ip
            logger.info(f"IPv6æ˜ å°„: {original} -> {fake_ip}")
            return fake_ip
            
        except ipaddress.AddressValueError:
            logger.warning(f"æ— æ•ˆçš„IPv6åœ°å€: {original}")
            return original
    
    def _action_domain(self, context_before: str, original: str, **kwargs) -> str:
        """åŸŸåå¤„ç†åŠ¨ä½œ"""
        if original in self.domain_cache:
            return self.domain_cache[original]
        
        # è§£æåŸŸå
        domain_lower = original.lower()
        parts = domain_lower.split('.')
        
        if len(parts) < 2:
            return original
        
        # åŸºäºåŸå§‹åŸŸåç”Ÿæˆå‡åŸŸå
        hash_seed = f"domain_{domain_lower}"
        
        # ç”Ÿæˆå­åŸŸå
        if len(parts) > 2:
            # å¤šçº§åŸŸåï¼Œä¿ç•™ç»“æ„
            subdomain_parts = []
            for i, part in enumerate(parts[:-2]):
                fake_part = f"sub{self._hash_to_range(f'{hash_seed}_{i}_{part}', 1, 999)}"
                subdomain_parts.append(fake_part)
            fake_domain = '.'.join(subdomain_parts) + '.example.com'
        else:
            # äºŒçº§åŸŸå
            fake_name = f"site{self._hash_to_range(hash_seed, 1, 9999)}"
            fake_domain = f"{fake_name}.example.com"
        
        self.domain_cache[original] = fake_domain
        logger.info(f"åŸŸåæ˜ å°„: {original} -> {fake_domain}")
        return fake_domain
    
    def _action_url(self, context_before: str, original: str, **kwargs) -> str:
        """URLå¤„ç†åŠ¨ä½œ"""
        try:
            parsed = urllib.parse.urlparse(original)
            
            # å¤„ç†åŸŸåéƒ¨åˆ†
            if parsed.netloc:
                fake_domain = self._action_domain("", parsed.netloc)
            else:
                fake_domain = "example.com"
            
            # å¤„ç†è·¯å¾„
            fake_path = parsed.path
            if fake_path:
                # ä¿ç•™æ–‡ä»¶æ‰©å±•å
                path_parts = fake_path.split('/')
                fake_path_parts = []
                
                for part in path_parts:
                    if not part:
                        fake_path_parts.append("")
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ‰©å±•å
                    if '.' in part:
                        name, ext = part.rsplit('.', 1)
                        hash_seed = f"path_{name}"
                        fake_name = f"page{self._hash_to_range(hash_seed, 1, 999)}"
                        fake_path_parts.append(f"{fake_name}.{ext}")
                    else:
                        hash_seed = f"path_{part}"
                        fake_name = f"dir{self._hash_to_range(hash_seed, 1, 999)}"
                        fake_path_parts.append(fake_name)
                
                fake_path = '/'.join(fake_path_parts)
            
            # å¤„ç†æŸ¥è¯¢å‚æ•°ï¼ˆä¿ç•™é”®åï¼Œæ··æ·†å€¼ï¼‰
            fake_query = ""
            if parsed.query:
                query_params = urllib.parse.parse_qsl(parsed.query)
                fake_params = []
                
                for key, value in query_params:
                    # ä¿ç•™é”®åï¼Œæ··æ·†å€¼
                    if value:
                        hash_seed = f"query_{key}_{value}"
                        fake_value = f"val{self._hash_to_range(hash_seed, 1, 999)}"
                    else:
                        fake_value = ""
                    fake_params.append(f"{key}={fake_value}")
                
                fake_query = '&'.join(fake_params)
            
            # é‡æ„URL
            fake_url = urllib.parse.urlunparse((
                parsed.scheme or 'https',
                fake_domain,
                fake_path,
                parsed.params,
                fake_query,
                parsed.fragment
            ))
            
            logger.info(f"URLæ˜ å°„: {original} -> {fake_url}")
            return fake_url
            
        except Exception as e:
            logger.warning(f"URLè§£æå¤±è´¥: {original} - {e}")
            return original
    
    def replace_interactive(self, text: str) -> str:
        """äº¤äº’å¼æ›¿æ¢æ–‡æœ¬ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
        matches = self.find_matches(text)
        
        if not matches:
            logger.info("æœªæ‰¾åˆ°éœ€è¦æ›¿æ¢çš„å†…å®¹")
            return text
        
        logger.info(f"æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…é¡¹")
        
        # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
        matches.reverse()
        result_text = text
        
        for i, match in enumerate(matches):
            print(f"\n=== åŒ¹é…é¡¹ {len(matches) - i}/{len(matches)} ===")
            print(f"åˆ†ç±»: {match.rule.category}")
            print(f"è§„åˆ™: {match.rule.pattern} ({match.rule.match_type})")
            print(f"å¤„ç†åŠ¨ä½œ: {match.rule.action}")
            print(f"åŒ¹é…å†…å®¹: {match.text}")
            print(f"ä¸Šä¸‹æ–‡: ...{match.context_before}[{match.text}]{match.context_after}...")
            
            # åº”ç”¨å¤„ç†åŠ¨ä½œ
            action_func = self.actions[match.rule.action]
            replacement = action_func(match.context_before, match.text, **match.groups)
            
            if replacement != match.text:
                print(f"å»ºè®®æ›¿æ¢ä¸º: {replacement}")
                
                while True:
                    choice = input("é€‰æ‹©æ“ä½œ [r]æ›¿æ¢ [s]è·³è¿‡ [q]é€€å‡º [e]ç¼–è¾‘: ").strip().lower()
                    
                    if choice in ['r', 'replace', '']:
                        # æ‰§è¡Œæ›¿æ¢ï¼ˆæ³¨æ„è¦è°ƒæ•´ä½ç½®ï¼Œå› ä¸ºå‰é¢å¯èƒ½æœ‰æ›¿æ¢ï¼‰
                        result_text = result_text[:match.start] + replacement + result_text[match.end:]
                        print(f"âœ… å·²æ›¿æ¢: {match.text} -> {replacement}")
                        break
                    elif choice in ['s', 'skip']:
                        print("â­ï¸ å·²è·³è¿‡")
                        break
                    elif choice in ['q', 'quit']:
                        print("ğŸ›‘ ç”¨æˆ·é€€å‡º")
                        return result_text
                    elif choice in ['e', 'edit']:
                        custom_replacement = input(f"è¯·è¾“å…¥è‡ªå®šä¹‰æ›¿æ¢å†…å®¹ (åŸå†…å®¹: {match.text}): ").strip()
                        if custom_replacement:
                            result_text = result_text[:match.start] + custom_replacement + result_text[match.end:]
                            print(f"âœ… å·²æ›¿æ¢: {match.text} -> {custom_replacement}")
                            break
                        else:
                            print("è¾“å…¥ä¸ºç©ºï¼Œè¯·é‡æ–°é€‰æ‹©")
                    else:
                        print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ r/s/q/e")
            else:
                print("ğŸ“ å¤„ç†åŠ¨ä½œæœªäº§ç”Ÿæ›¿æ¢")
        
        return result_text
    
    def process_file(self, input_file: str, output_file: str = None):
        """å¤„ç†markdownæ–‡ä»¶"""
        input_path = Path(input_file)
        if not input_path.exists():
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        
        logger.info(f"å¤„ç†æ–‡ä»¶: {input_file}")
        
        # è¯»å–æ–‡ä»¶
        with open(input_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # äº¤äº’å¼æ›¿æ¢
        result_content = self.replace_interactive(content)
        
        # è¾“å‡ºæ–‡ä»¶
        if output_file:
            output_path = Path(output_file)
        else:
            output_path = input_path.with_suffix('.sanitized.md')
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(result_content)
        
        logger.info(f"å¤„ç†å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {output_path}")
        return str(output_path)

def main():
    parser = argparse.ArgumentParser(description="Markdownæ•æ„Ÿä¿¡æ¯æ›¿æ¢å·¥å…·")
    parser.add_argument("--rules", "-r", required=True, help="CSVè§„åˆ™æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--input", "-i", required=True, help="è¾“å…¥Markdownæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤ä¸ºè¾“å…¥æ–‡ä»¶å.sanitized.md)")
    parser.add_argument("--context", "-c", type=int, default=20, help="ä¸Šä¸‹æ–‡å­—ç¬¦æ•°é‡ (é»˜è®¤: 20)")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†è¾“å‡º")
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        # åˆ›å»ºæ›¿æ¢å™¨
        replacer = SensitiveDataReplacer(context_chars=args.context)
        
        # åŠ è½½è§„åˆ™
        replacer.load_rules(args.rules)
        
        # å¤„ç†æ–‡ä»¶
        output_file = replacer.process_file(args.input, args.output)
        
        print(f"\nâœ… å¤„ç†å®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    main()
